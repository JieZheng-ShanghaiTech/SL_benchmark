{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "import scipy.sparse as sp\n",
    "# import wandb\n",
    "# import weave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = '../results/metrics/'\n",
    "# nsms = os.listdir(base_path)\n",
    "# methods = os.listdir('')\n",
    "# nsm = 'random'\n",
    "# method = 'sl2mf'\n",
    "# path = f'../results/metrics/{nsm}/{method}'\n",
    "# res_name = os.listdir(path)\n",
    "# # res_name\n",
    "# pd.read_csv(f'{path}/{res_name[1]}').loc[2,:].values[3:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../results/metrics'\n",
    "# base_path = '../results/metrics_wo_compt'\n",
    "summary_res_df = pd.DataFrame(columns=['AUROC', 'AUPR', 'F1', 'N10', 'N20', 'N50', 'R10', 'R20', 'R50', 'P10', 'P20', 'P50', 'M10', 'M20', 'M50'],\n",
    "                              index = ['CV1,1','CV2,1','CV3,1','CV1,5','CV2,5','CV3,5','CV1,20','CV2,20','CV3,20','CV1,50','CV2,50','CV3,50'])\n",
    "nsms = os.listdir(base_path)\n",
    "res_dict = {}\n",
    "for nsm in nsms:\n",
    "    res_dict[nsm]={}\n",
    "    methods = os.listdir(f'{base_path}/{nsm}')\n",
    "    for method in methods:\n",
    "        res_dict[nsm][method] = copy.deepcopy(summary_res_df)\n",
    "        res_name = os.listdir(f'{base_path}/{nsm}/{method}')\n",
    "        for n in res_name:\n",
    "            res = pd.read_csv(f'{base_path}/{nsm}/{method}/{n}')\n",
    "            res = res.loc[2,:].values[3:].astype(float)\n",
    "            n_split = n.split('_')\n",
    "            cvx,pnr = n_split[4],int(1/float(n_split[3]))\n",
    "            x_id = str(cvx)+','+str(pnr)\n",
    "            res_dict[nsm][method].loc[x_id,:] = res\n",
    "        # res_dict[nsm][method] = res_dict[nsm][method][['AUROC', 'AUPR', 'F1', 'N10', 'N20', 'N50', 'R10', 'R20', 'R50', 'P10', 'P20', 'P50', 'M10', 'M20', 'M50']]\n",
    "        res_dict[nsm][method].to_csv(f'../results/summary/summary_{nsm}_{method}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col_name = ['Model', 'NSM']\n",
    "for i in ['CV1,1','CV2,1','CV3,1','CV1,5','CV2,5','CV3,5','CV1,20','CV2,20','CV3,20','CV1,50','CV2,50','CV3,50']:\n",
    "    for j in ['AUROC', 'AUPR', 'F1', 'N10', 'N20', 'N50', 'R10', 'R20', 'R50', 'P10', 'P20', 'P50', 'M10', 'M20', 'M50']:\n",
    "        all_col_name.append(i+','+j)\n",
    "len(all_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.DataFrame(columns=all_col_name)\n",
    "score_values_df = pd.DataFrame(columns=all_col_name)\n",
    "score_values = np.zeros((36,182), dtype=object)\n",
    "score_values[:,1] = ['random']*12+['exp']*12+['dep']*12\n",
    "nsms = ['random', 'exp', 'dep']\n",
    "# models = ['kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl']\n",
    "# models = ['kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl','kg4sl']\n",
    "# models = ['sl2mf', 'slmgae', 'cmfw', 'ddgcn', 'gcatsl', 'grsmf', 'kg4sl', 'mge4sl', 'nsf4sl', 'pilsl', 'ptgnn']\n",
    "models = ['sl2mf', 'slmgae', 'cmfw', 'ddgcn', 'gcatsl', 'grsmf', 'kg4sl', 'mge4sl', 'nsf4sl', 'pilsl', 'ptgnn','slgnn']\n",
    "for i in range(36):\n",
    "    score_values[i,0] = models[i%12]\n",
    "    model = models[i%12]\n",
    "    nsm = nsms[i//12]\n",
    "    for j in range(2,182):\n",
    "        cvx,pnr,met = all_col_name[j].split(',')\n",
    "        r = cvx+','+pnr\n",
    "        c = met\n",
    "        try:\n",
    "            score_values_df.loc[i,all_col_name[j]] = res_dict[nsm][model].loc[r,c]\n",
    "            score_values_df.loc[i,'Model']=model\n",
    "            score_values_df.loc[i,'NSM']=nsm\n",
    "            \n",
    "        except:\n",
    "            # score_values_df.loc[i,all_col_name[j]] = res_dict[nsm][model].loc[r,c]\n",
    "            score_values_df.loc[i,'Model']=model\n",
    "            score_values_df.loc[i,'NSM']=nsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.DataFrame(data = score_values,columns=all_col_name)\n",
    "# new_df\n",
    "score_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_values_df.to_csv('summary_all_matrics_wo_compt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_values_df.fillna(np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_score_values_df = score_values_df[list(score_values_df.columns[:2])+[c for c in score_values_df.columns if any(['F1' in c,'F1' in c,'F1' in c])]]\n",
    "sub_score_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = sns.cubehelix_palette(as_cmap=True, nan_color='gray')\n",
    "f, ax = plt.subplots(figsize=(10, 12))\n",
    "sns.heatmap(sub_score_values_df.iloc[:,2:]-wo_sub_score_values_df.iloc[:,2:],annot=True,fmt='.3f',annot_kws={\"size\": 9},ax=ax,yticklabels=score_values_df['Model'],cbar=False)\n",
    "# sns.heatmap(sub_score_values_df.iloc[:,2:],annot=True,fmt='.3f',annot_kws={\"size\": 9},ax=ax,yticklabels=score_values_df['Model'],cbar=False)\n",
    "ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "# 将X轴刻度标签移动到顶部\n",
    "ax.xaxis.tick_top()\n",
    "# （可选）旋转X轴标签以改善可读性，这里设置为水平方向\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('mdamb231_gene_frequency_heatmap_top50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = sns.cubehelix_palette(as_cmap=True, nan_color='gray')\n",
    "f, ax = plt.subplots(figsize=(10, 12))\n",
    "sns.heatmap(sub_score_values_df.iloc[:,2:],\n",
    "            annot=True,fmt='.3f',annot_kws={\"size\": 9},ax=ax,yticklabels=pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/src/summary_all_matrics.csv')['Model'],cbar=False)\n",
    "ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "# 将X轴刻度标签移动到顶部\n",
    "ax.xaxis.tick_top()\n",
    "# （可选）旋转X轴标签以改善可读性，这里设置为水平方向\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('mdamb231_gene_frequency_heatmap_top50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict['random'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare w/wo compute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_res = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/src/summary_all_matrics.csv')\n",
    "summary_res_wo_compt = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/src/summary_all_matrics_wo_compt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_res(res,nsm):\n",
    "    model_order = ['GRSMF', 'SL2MF', 'CMFW', 'SLMGAE', 'NSF4SL', 'PTGNN', 'PiLSL', 'KG4SL','SLGNN', 'DDGCN', 'GCATSL', 'MGE4SL']\n",
    "    res = res[res['NSM']==nsm]\n",
    "    res['Model'] = res['Model'].apply(lambda x: x.upper())\n",
    "    res.index = res['Model']\n",
    "    res = res.loc[[e.upper() for e in model_order]]\n",
    "    res['Model'] = model_order\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_res = extract_res(summary_res,'random')\n",
    "random_res_wo_compt = extract_res(summary_res_wo_compt,'random')\n",
    "\n",
    "exp_res = extract_res(summary_res,'exp')\n",
    "exp_res_wo_compt = extract_res(summary_res_wo_compt,'exp')\n",
    "\n",
    "dep_res = extract_res(summary_res,'dep')\n",
    "dep_res_wo_compt = extract_res(summary_res_wo_compt,'dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_random_res = random_res[sorted([c for c in random_res.columns if all(['F1' in c,'F1' in c,'F1' in c])])]\n",
    "f1_exp_res = exp_res[sorted([c for c in exp_res.columns if all(['F1' in c,'F1' in c,'F1' in c])])]\n",
    "f1_dep_res = dep_res[sorted([c for c in dep_res.columns if all(['F1' in c,'F1' in c,'F1' in c])])]\n",
    "n10_random_res = random_res[sorted([c for c in random_res.columns if all(['N10' in c,'N10' in c,'N10' in c])])]\n",
    "n10_exp_res = exp_res[sorted([c for c in exp_res.columns if all(['N10' in c,'N10' in c,'N10' in c])])]\n",
    "n10_dep_res = dep_res[sorted([c for c in dep_res.columns if all(['N10' in c,'N10' in c,'N10' in c])])]\n",
    "\n",
    "f1_random_res_wo_compt = random_res_wo_compt[sorted([c for c in random_res_wo_compt.columns if all(['F1' in c,'F1' in c,'F1' in c])])]\n",
    "f1_exp_res_wo_compt = exp_res_wo_compt[sorted([c for c in exp_res_wo_compt.columns if all(['F1' in c,'F1' in c,'F1' in c])])]\n",
    "f1_dep_res_wo_compt = dep_res_wo_compt[sorted([c for c in dep_res_wo_compt.columns if all(['F1' in c,'F1' in c,'F1' in c])])]\n",
    "n10_random_res_wo_compt = random_res_wo_compt[sorted([c for c in random_res_wo_compt.columns if all(['N10' in c,'N10' in c,'N10' in c])])]\n",
    "n10_exp_res_wo_compt = exp_res_wo_compt[sorted([c for c in exp_res_wo_compt.columns if all(['N10' in c,'N10' in c,'N10' in c])])]\n",
    "n10_dep_res_wo_compt = dep_res_wo_compt[sorted([c for c in dep_res_wo_compt.columns if all(['N10' in c,'N10' in c,'N10' in c])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_classifi_score(class_res):\n",
    "    cv1_res = class_res[[c for c in class_res.columns if 'CV1' in c]]\n",
    "    cv2_res = class_res[[c for c in class_res.columns if 'CV2' in c]]\n",
    "    cv3_res = class_res[[c for c in class_res.columns if 'CV3' in c]]\n",
    "    class_score_df = pd.DataFrame()\n",
    "    class_score_df['CV1'] = cv1_res.values[:,:9].mean(axis=1)\n",
    "    class_score_df['CV2'] = cv2_res.values[:,:9].mean(axis=1)\n",
    "    class_score_df['CV3'] = cv3_res.values[:,:9].mean(axis=1)\n",
    "    class_score_df.index = class_res.index\n",
    "    class_score_df['Weighted_123'] = class_score_df['CV1']*0.4+class_score_df['CV2']*0.5+class_score_df['CV3']*0.1\n",
    "    class_score_df = class_score_df.sort_values(by='Weighted_123',ascending=False)\n",
    "    class_score_df['Rank_123'] = list(range(1,13))\n",
    "    class_score_df['Weighted_12'] = class_score_df['CV1']*0.4+class_score_df['CV2']*0.6\n",
    "    class_score_df = class_score_df.sort_values(by='Weighted_12',ascending=False)\n",
    "    class_score_df['Rank_12'] = list(range(1,13))\n",
    "    class_score_df = class_score_df.loc[cv3_res.index.to_list()]\n",
    "    return class_score_df\n",
    "\n",
    "def cal_ranking_score(class_res):\n",
    "    class_res.loc['PILSL'] = [np.nan]*class_res.shape[1]\n",
    "    cv1_res = class_res[[c for c in class_res.columns if 'CV1' in c]]\n",
    "    cv2_res = class_res[[c for c in class_res.columns if 'CV2' in c]]\n",
    "    cv3_res = class_res[[c for c in class_res.columns if 'CV3' in c]]\n",
    "    class_score_df = pd.DataFrame()\n",
    "    class_score_df['CV1'] = cv1_res.values[:,:9].mean(axis=1)\n",
    "    class_score_df['CV2'] = cv2_res.values[:,:9].mean(axis=1)\n",
    "    class_score_df['CV3'] = cv3_res.values[:,:9].mean(axis=1)\n",
    "    class_score_df.index = class_res.index\n",
    "    class_score_df['Weighted_123'] = class_score_df['CV1']*0.4+class_score_df['CV2']*0.5+class_score_df['CV3']*0.1\n",
    "    class_score_df = class_score_df.sort_values(by='Weighted_123',ascending=False)\n",
    "    class_score_df['Rank_123'] = list(range(1,13))\n",
    "    class_score_df['Weighted_12'] = class_score_df['CV1']*0.4+class_score_df['CV2']*0.6\n",
    "    class_score_df = class_score_df.sort_values(by='Weighted_12',ascending=False)\n",
    "    class_score_df['Rank_12'] = list(range(1,13))\n",
    "    class_score_df = class_score_df.loc[cv3_res.index.to_list()]\n",
    "    return class_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_overall_score(class_res,rank_res):\n",
    "    over_all_123 = pd.DataFrame((class_res['Weighted_123'].values+rank_res['Weighted_123'].values)/2,columns=['Weighted_123'])\n",
    "    over_all_12 = pd.DataFrame((class_res['Weighted_12'].values+rank_res['Weighted_12'].values)/2,columns=['Weighted_12'])\n",
    "    overall = pd.concat([over_all_123,over_all_12],axis=1)\n",
    "    overall.index = class_res.index\n",
    "    overall.loc['PILSL'] = [class_res['Weighted_123'].values[6]/2,class_res['Weighted_12'].values[6]/2]\n",
    "    overall = overall.sort_values(by='Weighted_123',ascending=False)\n",
    "    overall['Rank_123'] = list(range(1,13))\n",
    "    overall = overall.sort_values(by='Weighted_12',ascending=False)\n",
    "    overall['Rank_12'] = list(range(1,13))\n",
    "    overall = overall.loc[class_res.index.to_list()]\n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_random_res = random_res[sorted([c for c in random_res.columns if any(['AUROC' in c,'AUPR' in c,'F1' in c])])]\n",
    "class_exp_res = exp_res[sorted([c for c in exp_res.columns if any(['AUROC' in c,'AUPR' in c,'F1' in c])])]\n",
    "class_dep_res = dep_res[sorted([c for c in dep_res.columns if any(['AUROC' in c,'AUPR' in c,'F1' in c])])]\n",
    "rank_random_res = random_res[sorted([c for c in random_res.columns if any(['N10' in c,'R10' in c,'P10' in c])])]\n",
    "rank_exp_res = exp_res[sorted([c for c in exp_res.columns if any(['N10' in c,'R10' in c,'P10' in c])])]\n",
    "rank_dep_res = dep_res[sorted([c for c in dep_res.columns if any(['N10' in c,'R10' in c,'P10' in c])])]\n",
    "\n",
    "class_random_res_wo_compt = random_res_wo_compt[sorted([c for c in random_res_wo_compt.columns if any(['AUROC' in c,'AUPR' in c,'F1' in c])])]\n",
    "class_exp_res_wo_compt = exp_res_wo_compt[sorted([c for c in exp_res_wo_compt.columns if any(['AUROC' in c,'AUPR' in c,'F1' in c])])]\n",
    "class_dep_res_wo_compt = dep_res_wo_compt[sorted([c for c in dep_res_wo_compt.columns if any(['AUROC' in c,'AUPR' in c,'F1' in c])])]\n",
    "rank_random_res_wo_compt = random_res_wo_compt[sorted([c for c in random_res_wo_compt.columns if any(['N10' in c,'R10' in c,'P10' in c])])]\n",
    "rank_exp_res_wo_compt = exp_res_wo_compt[sorted([c for c in exp_res_wo_compt.columns if any(['N10' in c,'R10' in c,'P10' in c])])]\n",
    "rank_dep_res_wo_compt = dep_res_wo_compt[sorted([c for c in dep_res_wo_compt.columns if any(['N10' in c,'R10' in c,'P10' in c])])]\n",
    "\n",
    "class_score_random = cal_classifi_score(class_random_res)\n",
    "class_score_exp = cal_classifi_score(class_exp_res)\n",
    "class_score_dep = cal_classifi_score(class_dep_res)\n",
    "class_score_random_wo_compt = cal_classifi_score(class_random_res_wo_compt)\n",
    "class_score_exp_wo_compt = cal_classifi_score(class_exp_res_wo_compt)\n",
    "class_score_dep_wo_compt = cal_classifi_score(class_dep_res_wo_compt)\n",
    "\n",
    "rank_score_random = cal_ranking_score(rank_random_res)\n",
    "rank_score_exp = cal_ranking_score(rank_exp_res)\n",
    "rank_score_dep = cal_ranking_score(rank_dep_res)\n",
    "rank_score_random_wo_compt = cal_ranking_score(rank_random_res_wo_compt)\n",
    "rank_score_exp_wo_compt = cal_ranking_score(rank_exp_res_wo_compt)\n",
    "rank_score_dep_wo_compt = cal_ranking_score(rank_dep_res_wo_compt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_score_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_score_random_wo_compt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_overall_score(class_score_random,rank_score_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_overall_score(class_score_dep,rank_score_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_overall_score(class_score_exp,rank_score_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_random_res_wo_compt[['CV1,1,N10','CV1,5,N10','CV1,20,N10','CV1,50,N10']].round(3).to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(class_score_dep['Weighted_123']+rank_score_dep['Weighted_123'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(class_random_res[['CV3,1,F1','CV3,5,F1','CV3,20,F1','CV3,50,F1']].round(3)).to_csv('./tmp.csv')\n",
    "# (class_random_res[['CV1,1,AUROC','CV1,1,AUPR','CV1,1,F1','CV1,5,AUROC','CV1,5,AUPR','CV1,5,F1','CV1,20,AUROC','CV1,20,AUPR','CV1,20,F1','CV1,50,AUROC','CV1,50,AUPR','CV1,50,F1']].round(3)*100).T.to_csv('./tmp.csv')\n",
    "# class_exp_res_wo_compt[['CV1,1,AUROC','CV1,5,AUROC','CV1,20,AUROC','CV1,50,AUROC']]\n",
    "# class_exp_res_wo_compt[['CV1,1,F1','CV1,5,F1','CV1,20,F1','CV1,50,F1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_random_res[['CV2,1,F1','CV2,5,F1','CV2,20,F1','CV2,50,F1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_score_random = class_score_random.rename(columns={'CV1':'CV1_random','CV2':'CV2_random','CV3':'CV3_random','Weighted_123':'Weighted_123_random','Rank_123':'Rank_123_random','Weighted_12':'Weighted_12_random','Rank_12':'Rank_12_random'})\n",
    "class_score_exp = class_score_exp.rename(columns={'CV1':'CV1_exp','CV2':'CV2_exp','CV3':'CV3_exp','Weighted_123':'Weighted_123_exp','Rank_123':'Rank_123_exp','Weighted_12':'Weighted_12_exp','Rank_12':'Rank_12_exp'})\n",
    "class_score_dep = class_score_dep.rename(columns={'CV1':'CV1_dep','CV2':'CV2_dep','CV3':'CV3_dep','Weighted_123':'Weighted_123_dep','Rank_123':'Rank_123_dep','Weighted_12':'Weighted_12_dep','Rank_12':'Rank_12_dep'})\n",
    "all_class_score = pd.concat([class_score_random,class_score_exp,class_score_dep],axis=1)\n",
    "all_class_score = all_class_score[['Weighted_123_random','Weighted_123_exp','Weighted_123_dep']]\n",
    "all_class_score = all_class_score.rename(columns={'Weighted_123_random':'Random','Weighted_123_exp':'Exp','Weighted_123_dep':'Dep'})\n",
    "\n",
    "class_score_random_wo_compt = class_score_random_wo_compt.rename(columns={'CV1':'CV1_random','CV2':'CV2_random','CV3':'CV3_random','Weighted_123':'Weighted_123_random','Rank_123':'Rank_123_random','Weighted_12':'Weighted_12_random','Rank_12':'Rank_12_random'})\n",
    "class_score_exp_wo_compt = class_score_exp_wo_compt.rename(columns={'CV1':'CV1_exp','CV2':'CV2_exp','CV3':'CV3_exp','Weighted_123':'Weighted_123_exp','Rank_123':'Rank_123_exp','Weighted_12':'Weighted_12_exp','Rank_12':'Rank_12_exp'})\n",
    "class_score_dep_wo_compt = class_score_dep_wo_compt.rename(columns={'CV1':'CV1_dep','CV2':'CV2_dep','CV3':'CV3_dep','Weighted_123':'Weighted_123_dep','Rank_123':'Rank_123_dep','Weighted_12':'Weighted_12_dep','Rank_12':'Rank_12_dep'})\n",
    "all_class_score_wo_compt = pd.concat([class_score_random_wo_compt,class_score_exp_wo_compt,class_score_dep_wo_compt],axis=1)\n",
    "all_class_score_wo_compt = all_class_score_wo_compt[['Weighted_123_random','Weighted_123_exp','Weighted_123_dep']]\n",
    "all_class_score_wo_compt = all_class_score_wo_compt.rename(columns={'Weighted_123_random':'Random','Weighted_123_exp':'Exp','Weighted_123_dep':'Dep'})\n",
    "\n",
    "rank_score_random = rank_score_random.rename(columns={'CV1':'CV1_random','CV2':'CV2_random','CV3':'CV3_random','Weighted_123':'Weighted_123_random','Rank_123':'Rank_123_random','Weighted_12':'Weighted_12_random','Rank_12':'Rank_12_random'})\n",
    "rank_score_exp = rank_score_exp.rename(columns={'CV1':'CV1_exp','CV2':'CV2_exp','CV3':'CV3_exp','Weighted_123':'Weighted_123_exp','Rank_123':'Rank_123_exp','Weighted_12':'Weighted_12_exp','Rank_12':'Rank_12_exp'})\n",
    "rank_score_dep = rank_score_dep.rename(columns={'CV1':'CV1_dep','CV2':'CV2_dep','CV3':'CV3_dep','Weighted_123':'Weighted_123_dep','Rank_123':'Rank_123_dep','Weighted_12':'Weighted_12_dep','Rank_12':'Rank_12_dep'})\n",
    "all_rank_score = pd.concat([rank_score_random,rank_score_exp,rank_score_dep],axis=1)\n",
    "all_rank_score = all_rank_score[['Weighted_123_random','Weighted_123_exp','Weighted_123_dep']]\n",
    "all_rank_score = all_rank_score.rename(columns={'Weighted_123_random':'Random','Weighted_123_exp':'Exp','Weighted_123_dep':'Dep'})\n",
    "\n",
    "rank_score_random_wo_compt = rank_score_random_wo_compt.rename(columns={'CV1':'CV1_random','CV2':'CV2_random','CV3':'CV3_random','Weighted_123':'Weighted_123_random','Rank_123':'Rank_123_random','Weighted_12':'Weighted_12_random','Rank_12':'Rank_12_random'})\n",
    "rank_score_exp_wo_compt = rank_score_exp_wo_compt.rename(columns={'CV1':'CV1_exp','CV2':'CV2_exp','CV3':'CV3_exp','Weighted_123':'Weighted_123_exp','Rank_123':'Rank_123_exp','Weighted_12':'Weighted_12_exp','Rank_12':'Rank_12_exp'})\n",
    "rank_score_dep_wo_compt = rank_score_dep_wo_compt.rename(columns={'CV1':'CV1_dep','CV2':'CV2_dep','CV3':'CV3_dep','Weighted_123':'Weighted_123_dep','Rank_123':'Rank_123_dep','Weighted_12':'Weighted_12_dep','Rank_12':'Rank_12_dep'})\n",
    "all_rank_score_wo_compt = pd.concat([rank_score_random_wo_compt,rank_score_exp_wo_compt,rank_score_dep_wo_compt],axis=1)\n",
    "all_rank_score_wo_compt = all_rank_score_wo_compt[['Weighted_123_random','Weighted_123_exp','Weighted_123_dep']]\n",
    "all_rank_score_wo_compt = all_rank_score_wo_compt.rename(columns={'Weighted_123_random':'Random','Weighted_123_exp':'Exp','Weighted_123_dep':'Dep'})\n",
    "\n",
    "all_class_score_wo_compt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_score_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_c = all_class_score.melt(var_name='NSM', value_name='Score', value_vars=['Random','Exp','Dep'], ignore_index=False)\n",
    "plot_df_c['Model'] = plot_df_c.index\n",
    "plot_df_c['Task'] = 'Classification'\n",
    "plot_df_c_wo_compt = all_class_score_wo_compt.melt(var_name='NSM', value_name='Score', value_vars=['Random','Exp','Dep'], ignore_index=False)\n",
    "plot_df_c_wo_compt['Model'] = plot_df_c_wo_compt.index\n",
    "plot_df_c_wo_compt['Task'] = 'Classification'\n",
    "\n",
    "plot_df_r = all_rank_score.melt(var_name='NSM', value_name='Score', value_vars=['Random','Exp','Dep'], ignore_index=False)\n",
    "plot_df_r['Model'] = plot_df_r.index\n",
    "plot_df_r['Task'] = 'Ranking'\n",
    "plot_df_r_wo_compt = all_rank_score_wo_compt.melt(var_name='NSM', value_name='Score', value_vars=['Random','Exp','Dep'], ignore_index=False)\n",
    "plot_df_r_wo_compt['Model'] = plot_df_r_wo_compt.index\n",
    "plot_df_r_wo_compt['Task'] = 'Ranking'\n",
    "\n",
    "# plot_df = pd.concat([plot_df_c,plot_df_r],axis=0)\n",
    "# plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "models = ['GRSMF','SL$^2$MF','CMFW','SLMGAE','NSF4SL','PTGNN','PiLSL','KG4SL','SLGNN','DDGCN','GCATSL','MGE4SL']*3\n",
    "plot_df_c['Model'] = models\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.barplot(data=plot_df_c,y='Model',x='Score',hue='NSM',palette=['#F3A48A','#6FB0DE','#ABDE88'],alpha=0.9)\n",
    "# sns.barplot(data=plot_df_c_wo_compt,y='Model',x='Score',hue='NSM',alpha=0.5)\n",
    "ax.set(title='Comparison of classification scores',ylabel=\"\",xlabel=\"Classification scores\",xlim=(0,1))\n",
    "plt.xlim(0,1.25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./fig/class_scores.svg',format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "models = ['GRSMF','SL$^2$MF','CMFW','SLMGAE','NSF4SL','PTGNN','PiLSL','KG4SL','SLGNN','DDGCN','GCATSL','MGE4SL']*3\n",
    "plot_df_r['Model'] = models\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.barplot(data=plot_df_r,y='Model',x='Score',hue='NSM',palette=['#F3A48A','#6FB0DE','#ABDE88'],alpha=0.9)\n",
    "# sns.barplot(data=plot_df_c_wo_compt,y='Model',x='Score',hue='NSM',alpha=0.5)\n",
    "ax.set(title='Comparison of ranking scores',ylabel=\"\",xlabel=\"Ranking scores\",xlim=(0,1))\n",
    "plt.xlim(0,0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./fig/ranking_scores.svg',format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_score_random_wo_compt\n",
    "# rank_score_random_wo_compt\n",
    "class_score_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvalues = class_random_res_wo_compt[['CV1,1,F1','CV2,1,F1','CV3,1,F1']].values\n",
    "rvalues = n10_random_res_wo_compt[['CV1,1,N10','CV2,1,N10','CV3,1,N10']].values\n",
    "for i in range(12):\n",
    "    s = '&'.join([str(e.round(3)) for e in list(cvalues[i])+list(rvalues[i])])\n",
    "    print(f'{i+1} & {s} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n10_random_res_wo_compt[['CV1,1,N10','CV1,5,N10','CV1,20,N10','CV1,50,N10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_random_res_wo_compt[['CV1,1,F1','CV1,5,F1','CV1,20,F1','CV1,50,F1']]-class_random_res[['CV1,1,F1','CV1,5,F1','CV1,20,F1','CV1,50,F1']]\n",
    "class_random_res_wo_compt[['CV1,1,F1','CV2,1,F1','CV3,1,F1']]-class_random_res[['CV1,1,F1','CV2,1,F1','CV3,1,F1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_plot(f1_exp_res,f1_random_res,task,title,output_dir):\n",
    "    if task=='class':\n",
    "        senario_order = ['CV1,1,F1','CV1,5,F1','CV1,20,F1','CV1,50,F1','CV2,1,F1','CV2,5,F1','CV2,20,F1','CV2,50,F1','CV3,1,F1','CV3,5,F1','CV3,20,F1','CV3,50,F1']\n",
    "    elif task=='rank':\n",
    "        senario_order = ['CV1,1,N10','CV1,5,N10','CV1,20,N10','CV1,50,N10','CV2,1,N10','CV2,5,N10','CV2,20,N10','CV2,50,N10','CV3,1,N10','CV3,5,N10','CV3,20,N10','CV3,50,N10']\n",
    "    models = ['GRSMF','SL$^2$MF','CMFW','SLMGAE','NSF4SL','PTGNN','PiLSL','KG4SL','SLGNN','DDGCN','GCATSL','MGE4SL']\n",
    "    sns.set_theme(style=\"white\")\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(6, 5))\n",
    "    diff_score = f1_exp_res[senario_order]-f1_random_res[senario_order]\n",
    "    diff_score.index = models\n",
    "    if task=='rank':\n",
    "        diff_score.loc['PiLSL']=[np.nan]*diff_score.shape[1]\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(diff_score,cmap=sns.color_palette('vlag', as_cmap=True), center=0,\n",
    "                square=True, linewidths=.5)\n",
    "\n",
    "    ax.set(title=title,\n",
    "        ylabel=\"\",)\n",
    "    plt.xticks(rotation=36)\n",
    "    plt.savefig(f'./fig/{output_dir}.svg',format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_plot(f1_exp_res,f1_random_res,'class','F1 score difference between Exp and Random','f1_diff_exp')\n",
    "diff_plot(f1_dep_res,f1_random_res,'class','F1 score difference between Dep and Random','f1_diff_dep')\n",
    "diff_plot(f1_exp_res_wo_compt,f1_random_res_wo_compt,'class','F1 score difference between Exp and Random','f1_diff_exp_wo_compt')\n",
    "diff_plot(f1_dep_res_wo_compt,f1_random_res_wo_compt,'class','F1 score difference between Dep and Random','f1_diff_dep_wo_compt')\n",
    "\n",
    "diff_plot(n10_exp_res,n10_random_res,'rank','NDCG@10 score difference between Exp and Random','n10_diff_exp')\n",
    "diff_plot(n10_dep_res,n10_random_res,'rank','NDCG@10 score difference between Dep and Random','n10_diff_dep')\n",
    "diff_plot(n10_exp_res_wo_compt,n10_random_res_wo_compt,'rank','NDCG@10 score difference between Exp and Random','n10_diff_exp_wo_compt')\n",
    "diff_plot(n10_dep_res_wo_compt,n10_random_res_wo_compt,'rank','NDCG@10 score difference between Dep and Random','n10_diff_dep_wo_compt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic of GO PPI etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2go = pd.read_csv('/data/yimiaofeng/SLBench/scripts/orifiles/gene2go',sep='\\t')\n",
    "gene2go = gene2go[gene2go['#tax_id']==9606]\n",
    "meta_table_9845 = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/meta_table_9845.csv')\n",
    "# goa_human = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/src/goa_human.gaf',sep='\\t',header=None,skiprows=13)\n",
    "# goa_human=goa_human[goa_human[2].isin(set(meta_table_9845['symbol']))]\n",
    "# goa_human=goa_human[goa_human[8]=='P']\n",
    "gene2go = gene2go[gene2go['GeneID'].isin(set(meta_table_9845['entrez_id']))]\n",
    "gene2go = gene2go[gene2go['Category']=='Component']\n",
    "gene2go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGG_pathway_hsa_uniq = pd.read_csv('/data/yimiaofeng/SLBench/scripts/KEGG_pathway_hsa_uniq.txt',sep='|')\n",
    "KEGG_pathway_hsa_uniq = KEGG_pathway_hsa_uniq[KEGG_pathway_hsa_uniq['ko_name'].isin(set(meta_table_9845['symbol']))]\n",
    "len(set(KEGG_pathway_hsa_uniq['level3_pathway_id']))\n",
    "# KEGG_pathway_hsa_uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_sl_6460 = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/human_sl_6460.csv',index_col=0)\n",
    "human_sl_9845 = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/human_sl_9845.csv')\n",
    "meta_table_9845 = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/meta_table_9845.csv')\n",
    "all_uni_id_cut = np.load('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/wo_compt/cut_all_uni_id.npy',allow_pickle=True).item()\n",
    "human_sl_6460['unified_id_A'] = human_sl_6460['unified_id_A'].map(all_uni_id_cut)\n",
    "human_sl_6460['unified_id_B'] = human_sl_6460['unified_id_B'].map(all_uni_id_cut)\n",
    "# human_sl_6460 = human_sl_6460[human_sl_6460['unified_id_A']<human_sl_6460['unified_id_B']]\n",
    "# human_sl_9845 = human_sl_9845[human_sl_9845['unified_id_A']<human_sl_9845['unified_id_B']]\n",
    "sp_9845 = sp.csr_matrix((np.ones(len(human_sl_9845)), (human_sl_9845['unified_id_A'], human_sl_9845['unified_id_B'])), shape=(9845,9845),dtype=bool)\n",
    "sp_9845 = sp_9845+sp_9845.T\n",
    "sp_6460 = sp.csr_matrix((np.ones(len(human_sl_6460)), (human_sl_6460['unified_id_A'], human_sl_6460['unified_id_B'])), shape=(9845,9845),dtype=bool)\n",
    "sp_6460 = sp_6460+sp_6460.T\n",
    "sp_comp = sp_9845-sp_6460\n",
    "comp_sl = pd.DataFrame({'unified_id_A':sp_comp.nonzero()[0],'unified_id_B':sp_comp.nonzero()[1]})\n",
    "comp_sl = comp_sl[comp_sl['unified_id_A']<comp_sl['unified_id_B']]\n",
    "comp_sl\n",
    "# human_sl_6460\n",
    "# human_sl_9845\n",
    "# all_uni_id_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DepMap_Effect_corr = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/DepMap_Effect_corr.csv',index_col=0)\n",
    "DepMap_Expression_corr = pd.read_csv('/home/yimiaofeng/MyProject/SL-Benchmark/data/preprocessed_data/DepMap_Expression_corr.csv',index_col=0)\n",
    "DepMap_Effect_corr.columns = DepMap_Effect_corr.columns.map(int)\n",
    "DepMap_Effect_corr.index = DepMap_Effect_corr.index.map(int)\n",
    "DepMap_Expression_corr.columns = DepMap_Expression_corr.columns.map(int)\n",
    "DepMap_Expression_corr.index = DepMap_Expression_corr.index.map(int)\n",
    "idx = []\n",
    "for i in DepMap_Expression_corr.index:\n",
    "    if all(DepMap_Expression_corr.loc[i,:]==1):\n",
    "        idx.append(i)\n",
    "for i in idx:\n",
    "    DepMap_Expression_corr.loc[i,:]=[np.nan]*len(DepMap_Expression_corr.columns)\n",
    "    DepMap_Expression_corr.loc[:,i]=[np.nan]*len(DepMap_Expression_corr.columns)\n",
    "DepMap_Expression_corr = DepMap_Expression_corr[list(range(9845))]\n",
    "DepMap_Expression_corr = DepMap_Expression_corr.sort_index()\n",
    "DepMap_Expression_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_score(human_sl_6460,DepMap_Expression_corr):\n",
    "    score = []\n",
    "    for row in human_sl_6460.values:\n",
    "        score.append(DepMap_Expression_corr.loc[int(row[0]),int(row[1])])\n",
    "    return score\n",
    "human_sl_6460_exp = ex_score(human_sl_6460,DepMap_Expression_corr)\n",
    "human_sl_6460_dep = ex_score(human_sl_6460,DepMap_Effect_corr)\n",
    "human_sl_9845_exp = ex_score(human_sl_9845,DepMap_Expression_corr)\n",
    "human_sl_9845_dep = ex_score(human_sl_9845,DepMap_Effect_corr)\n",
    "comp_sl_exp = ex_score(comp_sl,DepMap_Expression_corr)\n",
    "comp_sl_dep = ex_score(comp_sl,DepMap_Effect_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot a histogram of the correlation\n",
    "sns.kdeplot(data=human_sl_6460_exp, fill=True,label='Dataset w/o computational labels',color='#F3A48A', common_norm = True, linewidth=0.5,alpha=.5)\n",
    "sns.kdeplot(data=human_sl_9845_exp, fill=True,label='Complete dataset',color='#6FB0DE', common_norm = True, linewidth=0.5,alpha=.5)\n",
    "sns.kdeplot(data=comp_sl_exp, fill=True,label='Computational labels',color='#ABDE88', common_norm = True, linewidth=0.5,alpha=.5)\n",
    "ax.legend(ncol=1, loc=\"upper left\", frameon=True)\n",
    "# plt.hist(sl_corr, bins=100)\n",
    "plt.xlabel('Correlation coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of gene expression correlation coefficients \\n from different source labels')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(0,3.3)\n",
    "# plt.show()\n",
    "plt.savefig('./fig/all_part_compt.svg',format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot a histogram of the correlation\n",
    "sns.kdeplot(data=human_sl_9845_exp, fill=True,label='Gene dependency score',color='#F3A48A', common_norm = True, linewidth=0.5,alpha=.5)\n",
    "sns.kdeplot(data=human_sl_9845_dep, fill=True,label='Gene expression',color='#6FB0DE', common_norm = True, linewidth=0.5,alpha=.5)\n",
    "# sns.kdeplot(data=comp_sl_exp, fill=True,label='Computational labels',color='#ABDE88', common_norm = True, linewidth=0.5,alpha=.5)\n",
    "ax.legend(ncol=1, loc=\"upper left\", frameon=True)\n",
    "# plt.hist(sl_corr, bins=100)\n",
    "plt.xlabel('Correlation coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of correlation coefficients \\n calculated using different data')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(0,7.6)\n",
    "# plt.show()\n",
    "plt.savefig('./fig/exp_dep.svg',format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "# Plot a histogram of the correlation\n",
    "sns.kdeplot(data=human_sl_6460_dep, fill=True,label='Dataset w/o computational labels', common_norm = True, linewidth=0.5,alpha=.8)\n",
    "sns.kdeplot(data=human_sl_9845_dep, fill=True,label='Complete dataset', common_norm = True, linewidth=0.5,alpha=.8)\n",
    "sns.kdeplot(data=comp_sl_dep, fill=True,label='Computational labels', common_norm = True, linewidth=0.5,alpha=.8)\n",
    "\n",
    "# plt.hist(sl_corr, bins=100)\n",
    "plt.xlabel('Gene dependency score correlation coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of known SL gene pairs')\n",
    "plt.xlim(-1,1)\n",
    "# plt.show()\n",
    "# plt.savefig('sl_corr_exp_18.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the following code is used to generate the score distribution figure for the paper\n",
    "#### **Must use parameter --save_mat to successfully run the following code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsm = 'random'\n",
    "base_path = f'../results/{nsm}_score_mats/'\n",
    "models = os.listdir(base_path)\n",
    "res_names = os.listdir(f'{base_path}/{models[0]}')\n",
    "res_names_classify = [i for i in res_names if 'classify' in i]\n",
    "res_names_ranking = [i for i in res_names if 'ranking' in i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples, neg_samples = np.load('../data/data_split/CV1_1.npy',allow_pickle=True)\n",
    "_, _, train_pos_kfold, test_pos_kfold = pos_samples\n",
    "_, _, train_neg_kfold, test_neg_kfold = neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_kfold[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvx = ['CV1', 'CV2', 'CV3']\n",
    "pnrs = [1.0,0.2,0.05,0.02]\n",
    "train_pos_scores = []\n",
    "train_neg_scores = []\n",
    "test_pos_scores =[]\n",
    "test_neg_scores =[]\n",
    "for fold_num in range(5):\n",
    "\n",
    "    score_mat = np.load(f'{base_path}/{models[0]}/slgnn_fold_{fold_num}_pos_neg_1.0_CV1_Random_ranking.npy')\n",
    "    train_pos_scores.append(score_mat[train_pos_kfold[fold_num][:,0],train_pos_kfold[fold_num][:,1]])\n",
    "    train_neg_scores.append(score_mat[train_neg_kfold[fold_num][:,0],train_neg_kfold[fold_num][:,1]])\n",
    "    test_pos_scores.append(score_mat[test_pos_kfold[fold_num][:,0],test_pos_kfold[fold_num][:,1]])\n",
    "    test_neg_scores.append(score_mat[test_neg_kfold[fold_num][:,0],test_neg_kfold[fold_num][:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def except_abnormal(data):\n",
    "    Q1 = np.percentile(data, 5)\n",
    "    Q3 = np.percentile(data, 95)\n",
    "    IQR = Q3 - Q1\n",
    "    filtered_data = data[(data >= Q1) & (data <= Q3)]\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(cv,pnr,fold_num,base_path,model):\n",
    "    pos_samples, neg_samples = np.load(f'../data/data_split/{cv}_{int(1/float(pnr))}.npy',allow_pickle=True)\n",
    "    _, _, train_pos_kfold, test_pos_kfold = pos_samples\n",
    "    _, _, train_neg_kfold, test_neg_kfold = neg_samples\n",
    "    \n",
    "    score_mat = np.load(f'{base_path}/{model}/{model}_fold_{fold_num}_pos_neg_{pnr}_{cv}_Random_classify.npy')\n",
    "\n",
    "    train_pos_score = except_abnormal(score_mat[train_pos_kfold[fold_num][:,0],train_pos_kfold[fold_num][:,1]])\n",
    "    train_neg_score = except_abnormal(score_mat[train_neg_kfold[fold_num][:,0],train_neg_kfold[fold_num][:,1]])\n",
    "    test_pos_score = except_abnormal(score_mat[test_pos_kfold[fold_num][:,0],test_pos_kfold[fold_num][:,1]])\n",
    "    test_neg_score = except_abnormal(score_mat[test_neg_kfold[fold_num][:,0],test_neg_kfold[fold_num][:,1]])\n",
    "        \n",
    "    return train_pos_score, train_neg_score, test_pos_score, test_neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_score_data(train_pos_score, train_neg_score, test_pos_score, test_neg_score):\n",
    "\n",
    "    plot_df = pd.DataFrame(columns=['Predict score','Sample type'])\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':train_pos_score,'Sample type':['$Train_{pos}$']*len(train_pos_score)}))\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':train_neg_score,'Sample type':['$Train_{neg}$']*len(train_neg_score)}))\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':test_pos_score,'Sample type':['$Test_{pos}$']*len(test_pos_score)}))\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':test_neg_score,'Sample type':['$Test_{neg}$']*len(test_neg_score)}))\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(all_score):\n",
    "    biggest_score = -np.inf\n",
    "    smallest_score = np.inf\n",
    "    for k in all_score.keys():\n",
    "        train_pos_score, train_neg_score, test_pos_score, test_neg_score = all_score[k]\n",
    "        max_score = max(train_pos_score.max(),train_neg_score.max(),test_pos_score.max(),test_neg_score.max())\n",
    "        min_score = min(train_pos_score.min(),train_neg_score.min(),test_pos_score.min(),test_neg_score.min())\n",
    "        if max_score>biggest_score:\n",
    "            biggest_score = max_score\n",
    "        if min_score<smallest_score:\n",
    "            smallest_score = min_score\n",
    "    new_all_score = {}\n",
    "    for k in all_score.keys():\n",
    "        train_pos_score, train_neg_score, test_pos_score, test_neg_score = all_score[k]\n",
    "        train_pos_score = (train_pos_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        train_neg_score = (train_neg_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        test_pos_score = (test_pos_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        test_neg_score = (test_neg_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        new_all_score[k] = train_pos_score, train_neg_score, test_pos_score, test_neg_score\n",
    "    return new_all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(fold_num,base_path,model):\n",
    "    processed_data = {}\n",
    "    for scenario in ['CV1_1.0','CV2_1.0','CV3_1.0','CV1_0.2','CV1_0.05','CV1_0.02']:\n",
    "        cv, pnr = scenario.split('_')\n",
    "        processed_data[scenario] = extract_data(cv,pnr,fold_num,base_path,model)\n",
    "    processed_data = normalize_data(processed_data)\n",
    "    processed_df = {}\n",
    "    for k in processed_data.keys():\n",
    "        train_pos_score, train_neg_score, test_pos_score, test_neg_score = processed_data[k]\n",
    "        processed_df[k] = load_score_data(train_pos_score, train_neg_score, test_pos_score, test_neg_score)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsm = 'random'\n",
    "base_path = f'../results/{nsm}_score_mats/'\n",
    "models = ['slgnn']\n",
    "# models = ['gcatsl','slmgae','sl2mf','cmfw','ddgcn','grsmf','kg4sl','mge4sl','nsf4sl','ptgnn']\n",
    "# fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "# fig_pos = [[0,0],[0,3],[0,4],[0,5],[0,1],[0,2]]\n",
    "fig_pos = [[0,0],[0,1],[0,2],[1,0],[1,1],[1,2]]\n",
    "\n",
    "for fold_num in range(5):\n",
    "    for model in models:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "        fig_num = 0\n",
    "        # fold_num = 4\n",
    "        plot_legend = False\n",
    "        processed_df = prepare_data(fold_num,base_path,model)\n",
    "        for k in processed_df.keys():\n",
    "            cv, pnr = k.split('_')\n",
    "            sns.kdeplot(data=processed_df[k], x='Predict score', hue='Sample type', fill=True, common_norm=False, alpha=.4, \n",
    "                        linewidth=0.5, ax=axes[fig_pos[fig_num][0],fig_pos[fig_num][1]], legend=plot_legend)\n",
    "            axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_title(f'SLGNN ({cv}, 1:{int(1/float(pnr))})')\n",
    "            axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_xlim(-0.1, 1.1)\n",
    "            fig_num +=1\n",
    "        # plt.savefig(f\"../results/score_dist/{model}_{fold_num}_Random.svg\", bbox_inches='tight')\n",
    "        plt.savefig(f\"../results/score_dist/{model}_{fold_num}_Random.svg\",format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvx = ['CV1', 'CV2', 'CV3']\n",
    "pnrs = [1.0,0.2,0.05,0.02]\n",
    "nsm = 'random'\n",
    "base_path = f'../results/{nsm}_score_mat/'\n",
    "models = ['gcatsl','slmgae','sl2mf','cmfw','ddgcn','grsmf','kg4sl','mge4sl','nsf4sl','ptgnn']\n",
    "# fig_pos = [[0,0],[0,3],[0,4],[0,5],[0,1],[0,2]]\n",
    "fig_pos = [[0,0],[1,0],[1,1],[1,2],[0,1],[0,2]]\n",
    "\n",
    "for fold_num in range(5):\n",
    "    for model in models:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "        fig_num = 0\n",
    "        # fold_num = 4\n",
    "        plot_legend = False\n",
    "        for cv in cvx:\n",
    "            if cv == 'CV1':\n",
    "                for pnr in pnrs:\n",
    "                    \n",
    "                    plot_df = load_score_data(cv,pnr,fold_num,base_path,model)\n",
    "                    \n",
    "                    sns.kdeplot(data=plot_df, x='Predict score', hue='Sample type', fill=True, common_norm=False, alpha=.4, \n",
    "                                linewidth=0.5, ax=axes[fig_pos[fig_num][0],fig_pos[fig_num][1]], legend=plot_legend)\n",
    "                    axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_title(f'{model.upper()} ({cv}, 1:{int(1/float(pnr))})')\n",
    "                    axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_xlim(-0.1, 1.1)\n",
    "                    \n",
    "                    # # 获取当前kdeplot的legend数据，以便后续使用\n",
    "                    # if legend_data is None:\n",
    "                    #     legend_data = [line for line in ax.lines if line.get_label() != \"_no_legend_\"]\n",
    "                    #     legend_labels = [line.get_label() for line in legend_data]\n",
    "\n",
    "                    fig_num +=1\n",
    "            else:\n",
    "                if fig_num == 5:\n",
    "                    plot_legend = True\n",
    "                pnr = 1.0\n",
    "                plot_df = load_score_data(cv,pnr,fold_num,base_path,model)\n",
    "\n",
    "                sns.kdeplot(data=plot_df, x='Predict score', hue='Sample type', fill=True, common_norm=False, alpha=.4, \n",
    "                            linewidth=0.5, ax=axes[fig_pos[fig_num][0],fig_pos[fig_num][1]], legend=plot_legend)\n",
    "                axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_title(f'{model.upper()} ({cv}, 1:{int(1/float(pnr))})')\n",
    "                axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_xlim(-0.1, 1.1)\n",
    "\n",
    "                fig_num +=1\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "        plt.savefig(f\"../results/score_dist/{model}_{fold_num}_Random.svg\",format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 'CV1'\n",
    "pnr = 1.0\n",
    "model = 'ptgnn'\n",
    "pos_samples, neg_samples = np.load(f'../data/data_split/{cv}_{int(1/float(pnr))}.npy',allow_pickle=True)\n",
    "_, _, train_pos_kfold, test_pos_kfold = pos_samples\n",
    "_, _, train_neg_kfold, test_neg_kfold = neg_samples\n",
    "\n",
    "score_mat = np.load(f'{base_path}{model}/{model}_fold_{fold_num}_pos_neg_{pnr}_{cv}_Random_classify.npy')\n",
    "train_pos_score = score_mat[train_pos_kfold[fold_num][:,0],train_pos_kfold[fold_num][:,1]]\n",
    "train_neg_score = score_mat[train_neg_kfold[fold_num][:,0],train_neg_kfold[fold_num][:,1]]\n",
    "test_pos_score = score_mat[test_pos_kfold[fold_num][:,0],test_pos_kfold[fold_num][:,1]]\n",
    "test_neg_score = score_mat[test_neg_kfold[fold_num][:,0],test_neg_kfold[fold_num][:,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.data.assign(target=iris.target_names[iris.target])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring import StreamTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "done_methods = ['KG4SL','NSF4SL','PTGNN','SLMGAE','PiLSL','CMFW','DDGCN','SL2MF','GRSMF','GCATSL','MGE4SL']\n",
    "# done_methods = ['PiLSL']\n",
    "runs = api.runs('slbench/Benchmarking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[0].scan_history(keys = ['test_M10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StreamTable(runs[0].history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLBench_good",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
