{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "import scipy.sparse as sp\n",
    "# import wandb\n",
    "# import weave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = '../results/metrics/'\n",
    "# nsms = os.listdir(base_path)\n",
    "# methods = os.listdir('')\n",
    "# nsm = 'random'\n",
    "# method = 'sl2mf'\n",
    "# path = f'../results/metrics/{nsm}/{method}'\n",
    "# res_name = os.listdir(path)\n",
    "# # res_name\n",
    "# pd.read_csv(f'{path}/{res_name[1]}').loc[2,:].values[3:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../results/metrics/'\n",
    "summary_res_df = pd.DataFrame(columns=['AUROC', 'AUPR', 'F1', 'N10', 'N20', 'N50', 'R10', 'R20', 'R50', 'P10', 'P20', 'P50', 'M10', 'M20', 'M50'],\n",
    "                              index = ['CV1,1','CV2,1','CV3,1','CV1,5','CV2,5','CV3,5','CV1,20','CV2,20','CV3,20','CV1,50','CV2,50','CV3,50'])\n",
    "nsms = os.listdir(base_path)\n",
    "res_dict = {}\n",
    "for nsm in nsms:\n",
    "    res_dict[nsm]={}\n",
    "    methods = os.listdir(f'{base_path}/{nsm}')\n",
    "    for method in methods:\n",
    "        res_dict[nsm][method] = copy.deepcopy(summary_res_df)\n",
    "        res_name = os.listdir(f'{base_path}/{nsm}/{method}')\n",
    "        for n in res_name:\n",
    "            res = pd.read_csv(f'{base_path}/{nsm}/{method}/{n}')\n",
    "            res = res.loc[2,:].values[3:].astype(float)\n",
    "            n_split = n.split('_')\n",
    "            cvx,pnr = n_split[4],int(1/float(n_split[3]))\n",
    "            x_id = str(cvx)+','+str(pnr)\n",
    "            res_dict[nsm][method].loc[x_id,:] = res\n",
    "        # res_dict[nsm][method] = res_dict[nsm][method][['AUROC', 'AUPR', 'F1', 'N10', 'N20', 'N50', 'R10', 'R20', 'R50', 'P10', 'P20', 'P50', 'M10', 'M20', 'M50']]\n",
    "        res_dict[nsm][method].to_csv(f'../results/summary/summary_{nsm}_{method}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col_name = ['Model', 'NSM']\n",
    "for i in ['CV1,1','CV2,1','CV3,1','CV1,5','CV2,5','CV3,5','CV1,20','CV2,20','CV3,20','CV1,50','CV2,50','CV3,50']:\n",
    "    for j in ['AUROC', 'AUPR', 'F1', 'N10', 'N20', 'N50', 'R10', 'R20', 'R50', 'P10', 'P20', 'P50', 'M10', 'M20', 'M50']:\n",
    "        all_col_name.append(i+','+j)\n",
    "len(all_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.DataFrame(columns=all_col_name)\n",
    "score_values = np.zeros((33,182), dtype=object)\n",
    "score_values[:,1] = ['random']*11+['exp']*11+['dep']*11\n",
    "nsms = ['random', 'exp', 'dep']\n",
    "models = ['sl2mf', 'slmgae', 'cmfw', 'ddgcn', 'gcatsl', 'grsmf', 'kg4sl', 'mge4sl', 'nsf4sl', 'pilsl', 'ptgnn']\n",
    "for i in range(33):\n",
    "    score_values[i,0] = models[i%11]\n",
    "    model = models[i%11]\n",
    "    nsm = nsms[i//11]\n",
    "    for j in range(2,182):\n",
    "        cvx,pnr,met = all_col_name[j].split(',')\n",
    "        r = cvx+','+pnr\n",
    "        c = met\n",
    "        score_values[i,j] = res_dict[nsm][model].loc[r,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(data = score_values,columns=all_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('summary_all_matrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict['random'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the following code is used to generate the score distribution figure for the paper\n",
    "#### **Must use parameter --save_mat to successfully run the following code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsm = 'random'\n",
    "base_path = f'../results/{nsm}_score_mat/'\n",
    "models = os.listdir(base_path)\n",
    "res_names = os.listdir(f'{base_path}/{models[-2]}')\n",
    "res_names_classify = [i for i in res_names if 'classify' in i]\n",
    "res_names_ranking = [i for i in res_names if 'ranking' in i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples, neg_samples = np.load('../data/data_split/CV1_1.npy',allow_pickle=True)\n",
    "_, _, train_pos_kfold, test_pos_kfold = pos_samples\n",
    "_, _, train_neg_kfold, test_neg_kfold = neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_kfold[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvx = ['CV1', 'CV2', 'CV3']\n",
    "pnrs = [1.0,0.2,0.05,0.02]\n",
    "train_pos_scores = []\n",
    "train_neg_scores = []\n",
    "test_pos_scores =[]\n",
    "test_neg_scores =[]\n",
    "for fold_num in range(5):\n",
    "\n",
    "    score_mat = np.load(f'{base_path}/{models[-2]}/slmgae_fold_{fold_num}_pos_neg_1.0_CV1_Random_ranking.npy')\n",
    "    train_pos_scores.append(score_mat[train_pos_kfold[fold_num][:,0],train_pos_kfold[fold_num][:,1]])\n",
    "    train_neg_scores.append(score_mat[train_neg_kfold[fold_num][:,0],train_neg_kfold[fold_num][:,1]])\n",
    "    test_pos_scores.append(score_mat[test_pos_kfold[fold_num][:,0],test_pos_kfold[fold_num][:,1]])\n",
    "    test_neg_scores.append(score_mat[test_neg_kfold[fold_num][:,0],test_neg_kfold[fold_num][:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def except_abnormal(data):\n",
    "    Q1 = np.percentile(data, 5)\n",
    "    Q3 = np.percentile(data, 95)\n",
    "    IQR = Q3 - Q1\n",
    "    filtered_data = data[(data >= Q1) & (data <= Q3)]\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(cv,pnr,fold_num,base_path,model):\n",
    "    pos_samples, neg_samples = np.load(f'../data/data_split/{cv}_{int(1/float(pnr))}.npy',allow_pickle=True)\n",
    "    _, _, train_pos_kfold, test_pos_kfold = pos_samples\n",
    "    _, _, train_neg_kfold, test_neg_kfold = neg_samples\n",
    "    \n",
    "    score_mat = np.load(f'{base_path}/{model}/{model}_fold_{fold_num}_pos_neg_{pnr}_{cv}_Random_classify.npy')\n",
    "\n",
    "    train_pos_score = except_abnormal(score_mat[train_pos_kfold[fold_num][:,0],train_pos_kfold[fold_num][:,1]])\n",
    "    train_neg_score = except_abnormal(score_mat[train_neg_kfold[fold_num][:,0],train_neg_kfold[fold_num][:,1]])\n",
    "    test_pos_score = except_abnormal(score_mat[test_pos_kfold[fold_num][:,0],test_pos_kfold[fold_num][:,1]])\n",
    "    test_neg_score = except_abnormal(score_mat[test_neg_kfold[fold_num][:,0],test_neg_kfold[fold_num][:,1]])\n",
    "        \n",
    "    return train_pos_score, train_neg_score, test_pos_score, test_neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_score_data(train_pos_score, train_neg_score, test_pos_score, test_neg_score):\n",
    "\n",
    "    plot_df = pd.DataFrame(columns=['Predict score','Sample type'])\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':train_pos_score,'Sample type':['$Train_{pos}$']*len(train_pos_score)}))\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':train_neg_score,'Sample type':['$Train_{neg}$']*len(train_neg_score)}))\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':test_pos_score,'Sample type':['$Test_{pos}$']*len(test_pos_score)}))\n",
    "    plot_df = plot_df.append(pd.DataFrame({'Predict score':test_neg_score,'Sample type':['$Test_{neg}$']*len(test_neg_score)}))\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(all_score):\n",
    "    biggest_score = -np.inf\n",
    "    smallest_score = np.inf\n",
    "    for k in all_score.keys():\n",
    "        train_pos_score, train_neg_score, test_pos_score, test_neg_score = all_score[k]\n",
    "        max_score = max(train_pos_score.max(),train_neg_score.max(),test_pos_score.max(),test_neg_score.max())\n",
    "        min_score = min(train_pos_score.min(),train_neg_score.min(),test_pos_score.min(),test_neg_score.min())\n",
    "        if max_score>biggest_score:\n",
    "            biggest_score = max_score\n",
    "        if min_score<smallest_score:\n",
    "            smallest_score = min_score\n",
    "    new_all_score = {}\n",
    "    for k in all_score.keys():\n",
    "        train_pos_score, train_neg_score, test_pos_score, test_neg_score = all_score[k]\n",
    "        train_pos_score = (train_pos_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        train_neg_score = (train_neg_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        test_pos_score = (test_pos_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        test_neg_score = (test_neg_score-smallest_score)/(biggest_score-smallest_score)\n",
    "        new_all_score[k] = train_pos_score, train_neg_score, test_pos_score, test_neg_score\n",
    "    return new_all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(fold_num,base_path,model):\n",
    "    processed_data = {}\n",
    "    for scenario in ['CV1_1.0','CV2_1.0','CV3_1.0','CV1_0.2','CV1_0.05']:\n",
    "        cv, pnr = scenario.split('_')\n",
    "        processed_data[scenario] = extract_data(cv,pnr,fold_num,base_path,model)\n",
    "    processed_data = normalize_data(processed_data)\n",
    "    processed_df = {}\n",
    "    for k in processed_data.keys():\n",
    "        train_pos_score, train_neg_score, test_pos_score, test_neg_score = processed_data[k]\n",
    "        processed_df[k] = load_score_data(train_pos_score, train_neg_score, test_pos_score, test_neg_score)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsm = 'random'\n",
    "base_path = f'../results/{nsm}_score_mat/'\n",
    "models = ['pilsl']\n",
    "# models = ['gcatsl','slmgae','sl2mf','cmfw','ddgcn','grsmf','kg4sl','mge4sl','nsf4sl','ptgnn']\n",
    "# fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "# fig_pos = [[0,0],[0,3],[0,4],[0,5],[0,1],[0,2]]\n",
    "fig_pos = [[0,0],[0,1],[0,2],[1,0],[1,1],[1,2]]\n",
    "\n",
    "for fold_num in range(5):\n",
    "    for model in models:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "        fig_num = 0\n",
    "        # fold_num = 4\n",
    "        plot_legend = False\n",
    "        processed_df = prepare_data(fold_num,base_path,model)\n",
    "        for k in processed_df.keys():\n",
    "            cv, pnr = k.split('_')\n",
    "            sns.kdeplot(data=processed_df[k], x='Predict score', hue='Sample type', fill=True, common_norm=False, alpha=.4, \n",
    "                        linewidth=0.5, ax=axes[fig_pos[fig_num][0],fig_pos[fig_num][1]], legend=plot_legend)\n",
    "            axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_title(f'PiLSL ({cv}, 1:{int(1/float(pnr))})')\n",
    "            axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_xlim(-0.1, 1.1)\n",
    "            fig_num +=1\n",
    "        plt.savefig(f\"../results/score_dist/{model}_{fold_num}_Random.svg\", bbox_inches='tight')\n",
    "        # plt.savefig(f\"../score_dist/{model}_{fold_num}_Random.svg\",format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvx = ['CV1', 'CV2', 'CV3']\n",
    "pnrs = [1.0,0.2,0.05,0.02]\n",
    "nsm = 'random'\n",
    "base_path = f'../results/{nsm}_score_mat/'\n",
    "models = ['gcatsl','slmgae','sl2mf','cmfw','ddgcn','grsmf','kg4sl','mge4sl','nsf4sl','ptgnn']\n",
    "# fig_pos = [[0,0],[0,3],[0,4],[0,5],[0,1],[0,2]]\n",
    "fig_pos = [[0,0],[1,0],[1,1],[1,2],[0,1],[0,2]]\n",
    "\n",
    "for fold_num in range(5):\n",
    "    for model in models:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "        fig_num = 0\n",
    "        # fold_num = 4\n",
    "        plot_legend = False\n",
    "        for cv in cvx:\n",
    "            if cv == 'CV1':\n",
    "                for pnr in pnrs:\n",
    "                    \n",
    "                    plot_df = load_score_data(cv,pnr,fold_num,base_path,model)\n",
    "                    \n",
    "                    sns.kdeplot(data=plot_df, x='Predict score', hue='Sample type', fill=True, common_norm=False, alpha=.4, \n",
    "                                linewidth=0.5, ax=axes[fig_pos[fig_num][0],fig_pos[fig_num][1]], legend=plot_legend)\n",
    "                    axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_title(f'{model.upper()} ({cv}, 1:{int(1/float(pnr))})')\n",
    "                    axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_xlim(-0.1, 1.1)\n",
    "                    \n",
    "                    # # 获取当前kdeplot的legend数据，以便后续使用\n",
    "                    # if legend_data is None:\n",
    "                    #     legend_data = [line for line in ax.lines if line.get_label() != \"_no_legend_\"]\n",
    "                    #     legend_labels = [line.get_label() for line in legend_data]\n",
    "\n",
    "                    fig_num +=1\n",
    "            else:\n",
    "                if fig_num == 5:\n",
    "                    plot_legend = True\n",
    "                pnr = 1.0\n",
    "                plot_df = load_score_data(cv,pnr,fold_num,base_path,model)\n",
    "\n",
    "                sns.kdeplot(data=plot_df, x='Predict score', hue='Sample type', fill=True, common_norm=False, alpha=.4, \n",
    "                            linewidth=0.5, ax=axes[fig_pos[fig_num][0],fig_pos[fig_num][1]], legend=plot_legend)\n",
    "                axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_title(f'{model.upper()} ({cv}, 1:{int(1/float(pnr))})')\n",
    "                axes[fig_pos[fig_num][0],fig_pos[fig_num][1]].set_xlim(-0.1, 1.1)\n",
    "\n",
    "                fig_num +=1\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "        plt.savefig(f\"../results/score_dist/{model}_{fold_num}_Random.svg\",format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 'CV1'\n",
    "pnr = 1.0\n",
    "model = 'ptgnn'\n",
    "pos_samples, neg_samples = np.load(f'../data/data_split/{cv}_{int(1/float(pnr))}.npy',allow_pickle=True)\n",
    "_, _, train_pos_kfold, test_pos_kfold = pos_samples\n",
    "_, _, train_neg_kfold, test_neg_kfold = neg_samples\n",
    "\n",
    "score_mat = np.load(f'{base_path}{model}/{model}_fold_{fold_num}_pos_neg_{pnr}_{cv}_Random_classify.npy')\n",
    "train_pos_score = score_mat[train_pos_kfold[fold_num][:,0],train_pos_kfold[fold_num][:,1]]\n",
    "train_neg_score = score_mat[train_neg_kfold[fold_num][:,0],train_neg_kfold[fold_num][:,1]]\n",
    "test_pos_score = score_mat[test_pos_kfold[fold_num][:,0],test_pos_kfold[fold_num][:,1]]\n",
    "test_neg_score = score_mat[test_neg_kfold[fold_num][:,0],test_neg_kfold[fold_num][:,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.data.assign(target=iris.target_names[iris.target])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring import StreamTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "done_methods = ['KG4SL','NSF4SL','PTGNN','SLMGAE','PiLSL','CMFW','DDGCN','SL2MF','GRSMF','GCATSL','MGE4SL']\n",
    "# done_methods = ['PiLSL']\n",
    "runs = api.runs('slbench/Benchmarking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[0].scan_history(keys = ['test_M10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StreamTable(runs[0].history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLBench_good",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
